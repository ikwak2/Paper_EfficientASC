{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mel-delta-deltadelta feature 추출하여 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas\n",
    "import librosa\n",
    "import numpy\n",
    "import pickle\n",
    "import soundfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dcase_util\n",
    "import tensorflow\n",
    "import keras\n",
    "\n",
    "\n",
    "print(\"Librosa version = \",librosa.__version__)\n",
    "print(\"keras version = \",keras.__version__)\n",
    "print(\"tensorflow version = \",tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fold='/Data/DCASE/DCASE2020t1_B/TAU-urban-acoustic-scenes-2020-3class-development/'\n",
    "\n",
    "meta_filename = os.path.join(data_fold, 'meta.csv')\n",
    "eval_filename= data_fold+'TAU-urban-acoustic-scenes-2020-3class-evaluation/evaluation_setup/fold1_test.csv'\n",
    "eval_audio='evalset/TAU-urban-acoustic-scenes-2020-3class-evaluation'\n",
    "meta_db = pandas.read_csv(meta_filename, '\\t')\n",
    "scene_labels = meta_db[\"scene_label\"].unique().tolist()   # 3개 indoor, outdoor, transportation\n",
    "identifiers = meta_db[\"identifier\"].unique().tolist() # 514개\n",
    "\n",
    "meta_db = meta_db.to_dict('records')\n",
    "for path in meta_db:\n",
    "    path['filename'] = os.path.join(data_fold, path['filename'])\n",
    "    \n",
    "eval_db=pandas.read_csv(eval_filename,'\\t')\n",
    "eval_db=eval_db.to_dict('records')\n",
    "eval_files=[]\n",
    "for path in eval_db:\n",
    "    path['filename'] = os.path.join(data_fold, eval_audio, path['filename'])\n",
    "    eval_files.append(path['filename'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## development set feature 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = '3class_melspecdelta_6'\n",
    "output_dir = os.path.join('features', feature)\n",
    "output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_filepath = [audio[\"filename\"] for audio in meta_db]\n",
    "audio_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import soundfile\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "feature = '3class_melspecdelta_6'\n",
    "\n",
    "sec=10\n",
    "n_channels=2\n",
    "sr = 48000\n",
    "win_length = 2048\n",
    "hop_length = 1024\n",
    "n_fft = 2048\n",
    "n_mels = 128\n",
    "fmin=0\n",
    "fmax=None\n",
    "htk = True\n",
    "\n",
    "output_dir = os.path.join('features', feature)\n",
    "num_files = len(audio_filepath)\n",
    "\n",
    "overlap = False\n",
    "#overlap = True\n",
    "if not os.path.exists(output_dir) or overlap == True:\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    for file_idx, filepath in enumerate(audio_filepath):\n",
    "        print(\"{}: Processing {} ({}/{})\".format(feature, filepath, file_idx+1, num_files))\n",
    "\n",
    "        _, current_last_level_path = os.path.split(filepath)\n",
    "        base_filename, _ = os.path.splitext(current_last_level_path)\n",
    "        output_path = os.path.join(output_dir, base_filename+'.npz')\n",
    "\n",
    "        NumTimeBins=int(np.ceil(sec*sr/hop_length))\n",
    "        LM_train = np.zeros((n_mels,NumTimeBins ,n_channels),'float32')\n",
    "        LM_train_l=np.zeros((n_mels,NumTimeBins ,n_channels),'float32')\n",
    "        LM_train_d = np.zeros((n_mels,NumTimeBins ,n_channels),'float32')\n",
    "        LM_train_dd = np.zeros((n_mels,NumTimeBins ,n_channels),'float32')\n",
    "        \n",
    "        stereo,fs = librosa.load(filepath,mono=False, sr=sr)\n",
    "        stereo=stereo.T\n",
    "        \n",
    "        for channel in range(n_channels):\n",
    "            LM_train[:,:,channel]= librosa.feature.melspectrogram(stereo[:,channel], \n",
    "                                                 sr=sr,\n",
    "                                                 n_fft=n_fft,\n",
    "                                                 hop_length=hop_length,\n",
    "                                                 n_mels=n_mels,\n",
    "                                                 fmin=fmin,\n",
    "                                                 fmax=fmax,\n",
    "                                                 htk=htk)\n",
    "            LM_train_l[:,:,channel] = np.log(LM_train[:,:,channel]+np.spacing(1))\n",
    "            LM_train_d[:,:,channel] = librosa.feature.delta(LM_train_l[:,:,channel])\n",
    "            LM_train_dd[:,:,channel] = librosa.feature.delta(LM_train_d[:,:,channel])\n",
    "        embedding= np.dstack((LM_train_l,LM_train_d,LM_train_dd))\n",
    "\n",
    "            \n",
    "        numpy.savez(output_path, embedding=embedding)\n",
    "\n",
    "        print(\"{}: Saved {} ({}/{})\".format(feature, output_path, file_idx+1, num_files))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
