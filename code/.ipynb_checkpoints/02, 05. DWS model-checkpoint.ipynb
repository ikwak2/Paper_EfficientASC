{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas\n",
    "import librosa\n",
    "import numpy\n",
    "import pickle\n",
    "import soundfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "import tensorflow.keras\n",
    "import scipy\n",
    "\n",
    "\n",
    "print(\"Librosa version = \",librosa.__version__)\n",
    "print(\"keras version = \",tensorflow.keras.__version__)\n",
    "print(\"tensorflow version = \",tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fold='/Data2/DCASE/DCASE2020t1_B/TAU-urban-acoustic-scenes-2020-3class-development/'\n",
    "train_filename = data_fold + 'evaluation_setup/fold1_train.csv'\n",
    "test_filename = data_fold + 'evaluation_setup/fold1_evaluate.csv'\n",
    "meta_filename = os.path.join(data_fold, 'meta.csv')\n",
    "meta_db = pandas.read_csv(meta_filename, '\\t')\n",
    "scene_labels = meta_db[\"scene_label\"].unique().tolist()   # 3개 indoor, outdoor, transportation\n",
    "identifiers = meta_db[\"identifier\"].unique().tolist() # 514개\n",
    "\n",
    "meta_db = meta_db.to_dict('records')\n",
    "for path in meta_db:\n",
    "    path['filename'] = os.path.join(data_fold, path['filename'])\n",
    "    \n",
    "train_db=pandas.read_csv(train_filename,'\\t')\n",
    "train_db = train_db.to_dict('records')\n",
    "train_files=[]\n",
    "for path in train_db:\n",
    "    split_filename=path['filename'].split('-')\n",
    "    path['filename'] = os.path.join(data_fold, path['filename'])\n",
    "    path['identifier']= '-'.join(split_filename[1:3])\n",
    "    train_files.append(path['filename'])\n",
    "    \n",
    "test_db=pandas.read_csv(test_filename,'\\t')\n",
    "test_db = test_db.to_dict('records')\n",
    "test_files=[]\n",
    "for path in test_db:\n",
    "    split_filename=path['filename'].split('-')\n",
    "    path['filename'] = os.path.join(data_fold, path['filename'])\n",
    "    path['identifier']= '-'.join(split_filename[1:3])\n",
    "    test_files.append(path['filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db=train_db\n",
    "\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "training_files = []\n",
    "validation_files = []\n",
    "\n",
    "\n",
    "for scene_id, scene_label in enumerate(scene_labels):\n",
    "    scene_meta = [file for file in db if file['scene_label']==scene_label]\n",
    "    data = {}\n",
    "\n",
    "    unique_identifiers = [file[\"identifier\"] for file in scene_meta]\n",
    "    unique_identifiers.sort()\n",
    "    for identifier in unique_identifiers:\n",
    "        path = identifier.split(\"-\")\n",
    "        new_value=[file[\"filename\"] for file in scene_meta if file[\"identifier\"]==identifier]\n",
    "        if path[0] not in data:\n",
    "            data[path[0]] = {}\n",
    "\n",
    "        data[path[0]][path[1]] = new_value\n",
    "        \n",
    "    current_scene_validation_amount = []\n",
    "    sets_candidates = []\n",
    "\n",
    "    identifier_first_level = list(data.keys())\n",
    "\n",
    "    for i in range(100):\n",
    "        current_validation_files = []\n",
    "        current_training_files = []\n",
    "\n",
    "        current_validation_identifiers2 = 0\n",
    "        for identifier1 in identifier_first_level:\n",
    "            current_ids = list(data[identifier1].keys())\n",
    "            random.shuffle(current_ids, random.random)\n",
    "\n",
    "            validation_split_index = int(numpy.ceil(0.3 * len(current_ids)))\n",
    "            current_validation = current_ids[0:validation_split_index]\n",
    "            current_training = current_ids[validation_split_index:]\n",
    "\n",
    "            for identifier2 in current_validation:\n",
    "                current_validation_files += data[identifier1][identifier2]\n",
    "\n",
    "            for identifier2 in current_training:\n",
    "                current_training_files += data[identifier1][identifier2]\n",
    "\n",
    "            current_validation_identifiers2 += len(current_validation)\n",
    "            \n",
    "        current_scene_validation_amount.append(\n",
    "            len(current_validation_files) / float(\n",
    "                len(current_validation_files) + len(current_training_files))\n",
    "        ) # 전체 v파일에 대해서 validation_files의 비율\n",
    "\n",
    "        sets_candidates.append({\n",
    "            'validation': current_validation_files,\n",
    "            'training': current_training_files,\n",
    "            'validation_identifiers1': len(identifier_first_level),\n",
    "            'validation_identifiers2': current_validation_identifiers2,\n",
    "        })\n",
    "\n",
    "    best_set_id = numpy.argmin(numpy.abs(numpy.array(current_scene_validation_amount) - 0.3))\n",
    "\n",
    "    validation_files += sets_candidates[best_set_id]['validation']\n",
    "    training_files += sets_candidates[best_set_id]['training']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train set: ', len(training_files))\n",
    "print('val set: ', len(validation_files))\n",
    "print('test set: ', len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name1 = '3class_melspecdelta_6'\n",
    "\n",
    "\n",
    "item_list_train = []\n",
    "item_list_validation = []\n",
    "item_list_test = []\n",
    "\n",
    "for item in meta_db:\n",
    "    _, current_last_level_path = os.path.split(item[\"filename\"])\n",
    "    base_filename, _ = os.path.splitext(current_last_level_path)\n",
    "\n",
    "    feature_filename1 = os.path.join(data_fold+'features/'\n",
    "                                     +feature_name1+'/'+base_filename+'.npz')\n",
    "\n",
    "    item_ = {\n",
    "        'data': {\n",
    "            'filename':[feature_filename1]\n",
    "        },\n",
    "        'meta': {\n",
    "            'label': item[\"scene_label\"]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if item[\"filename\"] in test_files:\n",
    "        item_list_test.append(item_)\n",
    "    elif item[\"filename\"] in training_files:\n",
    "        item_list_train.append(item_)\n",
    "    elif item[\"filename\"] in validation_files:\n",
    "        item_list_validation.append(item_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_list_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "Y_train = []\n",
    "for item in item_list_train:\n",
    "    binary_matrix = numpy.zeros((len(scene_labels), 1))\n",
    "    pos = scene_labels.index(item[\"meta\"][\"label\"])\n",
    "    binary_matrix[pos,:] = 1\n",
    "    \n",
    "    audio = numpy.load(item[\"data\"][\"filename\"][0])\n",
    "    embedding = audio['embedding']\n",
    "    \n",
    "    X_train.append(embedding)\n",
    "    Y_train.append(binary_matrix.T)\n",
    "    \n",
    "\n",
    "X_train = numpy.array(X_train)\n",
    "Y_train = numpy.vstack(Y_train)\n",
    "\n",
    "\n",
    "X_val = []\n",
    "Y_val = []\n",
    "for item in item_list_validation:\n",
    "    binary_matrix = numpy.zeros((len(scene_labels), 1))\n",
    "    pos = scene_labels.index(item[\"meta\"][\"label\"])\n",
    "    binary_matrix[pos,:] = 1\n",
    "    \n",
    "    audio = numpy.load(item[\"data\"][\"filename\"][0])\n",
    "    embedding = audio['embedding']\n",
    "    \n",
    "\n",
    "    X_val.append(embedding)\n",
    "    Y_val.append(binary_matrix.T)\n",
    "    \n",
    "\n",
    "X_val = numpy.array(X_val)\n",
    "Y_val = numpy.vstack(Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "Y_test = []\n",
    "for item in item_list_test:\n",
    "    binary_matrix = numpy.zeros((len(scene_labels), 1))\n",
    "    pos = scene_labels.index(item[\"meta\"][\"label\"])\n",
    "    binary_matrix[pos,:] = 1\n",
    "    \n",
    "    audio = numpy.load(item[\"data\"][\"filename\"][0])\n",
    "    embedding = audio['embedding']\n",
    "    \n",
    "    X_test.append(embedding)\n",
    "    Y_test.append(binary_matrix.T)\n",
    "    \n",
    "\n",
    "X_test = numpy.array(X_test)\n",
    "Y_test = numpy.vstack(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('deltas-deltadelta train shape: ',X_train.shape)\n",
    "print('deltas-deltadelta validation shape: ', X_val.shape)\n",
    "print('deltas-deltadelta test shape: ',X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_test_labels=[]\n",
    "for i in item_list_test:\n",
    "    if i['meta']['label']=='indoor':\n",
    "        dev_test_labels.append(0)\n",
    "    elif i['meta']['label']=='transportation':\n",
    "        dev_test_labels.append(1)\n",
    "    else:\n",
    "        dev_test_labels.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_val_labels=[]\n",
    "for i in item_list_validation:\n",
    "    if i['meta']['label']=='indoor':\n",
    "        dev_val_labels.append(0)\n",
    "    elif i['meta']['label']=='transportation':\n",
    "        dev_val_labels.append(1)\n",
    "    else:\n",
    "        dev_val_labels.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Mixup import MixupGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "\n",
    "import numpy\n",
    "import random\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import ZeroPadding2D,Input,Add, Permute, Cropping2D, Activation, Maximum,Dropout, Flatten, Dense, Conv2D, MaxPooling2D, MaxPool2D,BatchNormalization, Convolution2D, ReLU, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization as BN\n",
    "from tensorflow.keras.layers import DepthwiseConv2D, SeparableConv2D\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint,ReduceLROnPlateau\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from tensorflow.keras.layers import  concatenate\n",
    "\n",
    "import tensorflow.keras\n",
    "\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) DWS-ResNet  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Model_paper import resnet_dws2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dws2_model = resnet_dws2(Input(X_train.shape[1:]))\n",
    "dws2_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "\n",
    "dws2_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoidal_decay(e, start=0, end=100, lr_start=1e-3, lr_end=1e-5):\n",
    "    if e < start:\n",
    "        return lr_start\n",
    "    elif e > end:\n",
    "        return lr_end\n",
    "\n",
    "    middle = (start + end) / 2\n",
    "    s = lambda x: 1 / (1 + np.exp(-x))\n",
    "\n",
    "    return s(13 * (-e + middle) / np.abs(end - start)) * np.abs(lr_start - lr_end) + lr_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    model = resnet_dws2(Input(X_train.shape[1:]))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=100))\n",
    "\n",
    "    model_name = 'dws_'+ str(i)\n",
    "    checkpoint=\"checkpoints-10times/\"+model_name+'_'+\"cp.h5\"\n",
    "\n",
    "    mc = ModelCheckpoint(checkpoint, monitor='val_categorical_accuracy',\n",
    "                          verbose=True, save_best_only=True,\n",
    "                          mode ='auto', period =1)\n",
    "\n",
    "    TrainDataGen = MixupGenerator(X_train, \n",
    "                              Y_train, \n",
    "                              batch_size=64,\n",
    "                              alpha=0.4)()\n",
    "\n",
    "    history1 = model.fit_generator(TrainDataGen,\n",
    "                                   validation_data = (X_val, Y_val),\n",
    "                               epochs=100,\n",
    "                               callbacks=[lr, mc],\n",
    "                               steps_per_epoch=np.ceil(len(X_train)/64)\n",
    "                              )\n",
    "\n",
    "    scores = model.evaluate(X_test, Y_test, verbose=1)\n",
    "\n",
    "    print('Test loss:', scores[0])\n",
    "    print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    model_name = 'dws_'+ str(i)\n",
    "    checkpoint=\"checkpoints-10times/\"+model_name+'_'+\"cp.h5\"\n",
    "    dws2_model.load_weights(checkpoint)\n",
    "\n",
    "    scores_test = dws2_model.predict(X_test, verbose=1)\n",
    "    y_pred_test = np.argmax(scores_test,axis=1)\n",
    "    y_real = np.argmax(Y_test,axis=1)\n",
    "    Overall_accuracy = np.sum(y_pred_test==dev_test_labels)/len(X_test)\n",
    "    print('Test accuracy:', Overall_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### val acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    model_name = 'dws_'+ str(i)\n",
    "    checkpoint=\"checkpoints-10times/\"+model_name+'_'+\"cp.h5\"\n",
    "    model.load_weights(checkpoint)\n",
    "\n",
    "    scores_test = model.predict(X_val, verbose=1)\n",
    "    y_pred_test = np.argmax(scores_test,axis=1)\n",
    "    y_real = np.argmax(Y_val,axis=1)\n",
    "    Overall_accuracy = np.sum(y_pred_test==dev_val_labels)/len(X_val)\n",
    "    print('Test accuracy:', Overall_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) DWS-ResNet RF-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Model_paper import resnet_dws3, resnet_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet_dws3(Input(X_train.shape[1:]))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    model = resnet_dws3(Input(X_train.shape[1:]))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=100))\n",
    "\n",
    "    model_name = 'dws_rf1_'+ str(i)\n",
    "    checkpoint=\"checkpoints-10times/\"+model_name+'_'+\"cp.h5\"\n",
    "\n",
    "    mc = ModelCheckpoint(checkpoint, monitor='val_categorical_accuracy',\n",
    "                          verbose=True, save_best_only=True,\n",
    "                          mode ='auto', period =1)\n",
    "\n",
    "    TrainDataGen = MixupGenerator(X_train, \n",
    "                              Y_train, \n",
    "                              batch_size=64,\n",
    "                              alpha=0.4)()\n",
    "\n",
    "    history1 = model.fit_generator(TrainDataGen,\n",
    "                                   validation_data = (X_val, Y_val),\n",
    "                               epochs=100,\n",
    "                               callbacks=[lr, mc],\n",
    "                               steps_per_epoch=np.ceil(len(X_train)/64)\n",
    "                              )\n",
    "\n",
    "    scores = model.evaluate(X_test, Y_test, verbose=1)\n",
    "\n",
    "    print('Test loss:', scores[0])\n",
    "    print('Test accuracy:', scores[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    model_name = 'dws_rf1_'+ str(i)\n",
    "    checkpoint=\"checkpoints-10times/\"+model_name+'_'+\"cp.h5\"\n",
    "    model.load_weights(checkpoint)\n",
    "\n",
    "    scores_test = model.predict(X_test, verbose=1)\n",
    "    y_pred_test = np.argmax(scores_test,axis=1)\n",
    "    y_real = np.argmax(Y_test,axis=1)\n",
    "    Overall_accuracy = np.sum(y_pred_test==dev_test_labels)/len(X_test)\n",
    "    print('Test accuracy:', Overall_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### val acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    model_name = 'dws_rf1_'+ str(i)\n",
    "    checkpoint=\"checkpoints-10times/\"+model_name+'_'+\"cp.h5\"\n",
    "    model.load_weights(checkpoint)\n",
    "\n",
    "    scores_test = model.predict(X_val, verbose=1)\n",
    "    y_pred_test = np.argmax(scores_test,axis=1)\n",
    "    y_real = np.argmax(Y_val,axis=1)\n",
    "    Overall_accuracy = np.sum(y_pred_test==dev_val_labels)/len(X_val)\n",
    "    print('Test accuracy:', Overall_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
