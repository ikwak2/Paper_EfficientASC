{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[2], 'GPU')\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas\n",
    "import librosa\n",
    "import numpy\n",
    "import pickle\n",
    "import soundfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "import tensorflow.keras\n",
    "import scipy\n",
    "\n",
    "\n",
    "print(\"Librosa version = \",librosa.__version__)\n",
    "print(\"keras version = \",tensorflow.keras.__version__)\n",
    "print(\"tensorflow version = \",tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fold='/Data2/DCASE/DCASE2020t1_B/TAU-urban-acoustic-scenes-2020-3class-development/'\n",
    "train_filename = data_fold + 'evaluation_setup/fold1_train.csv'\n",
    "test_filename = data_fold + 'evaluation_setup/fold1_evaluate.csv'\n",
    "meta_filename = os.path.join(data_fold, 'meta.csv')\n",
    "meta_db = pandas.read_csv(meta_filename, '\\t')\n",
    "scene_labels = meta_db[\"scene_label\"].unique().tolist()   # 3개 indoor, outdoor, transportation\n",
    "identifiers = meta_db[\"identifier\"].unique().tolist() # 514개\n",
    "\n",
    "meta_db = meta_db.to_dict('records')\n",
    "for path in meta_db:\n",
    "    path['filename'] = os.path.join(data_fold, path['filename'])\n",
    "    \n",
    "train_db=pandas.read_csv(train_filename,'\\t')\n",
    "train_db = train_db.to_dict('records')\n",
    "train_files=[]\n",
    "for path in train_db:\n",
    "    split_filename=path['filename'].split('-')\n",
    "    path['filename'] = os.path.join(data_fold, path['filename'])\n",
    "    path['identifier']= '-'.join(split_filename[1:3])\n",
    "    train_files.append(path['filename'])\n",
    "    \n",
    "test_db=pandas.read_csv(test_filename,'\\t')\n",
    "test_db = test_db.to_dict('records')\n",
    "test_files=[]\n",
    "for path in test_db:\n",
    "    split_filename=path['filename'].split('-')\n",
    "    path['filename'] = os.path.join(data_fold, path['filename'])\n",
    "    path['identifier']= '-'.join(split_filename[1:3])\n",
    "    test_files.append(path['filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db=train_db\n",
    "\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "training_files = []\n",
    "validation_files = []\n",
    "\n",
    "\n",
    "for scene_id, scene_label in enumerate(scene_labels):\n",
    "    scene_meta = [file for file in db if file['scene_label']==scene_label]\n",
    "    data = {}\n",
    "\n",
    "    unique_identifiers = [file[\"identifier\"] for file in scene_meta]\n",
    "    unique_identifiers.sort()\n",
    "    for identifier in unique_identifiers:\n",
    "        path = identifier.split(\"-\")\n",
    "        new_value=[file[\"filename\"] for file in scene_meta if file[\"identifier\"]==identifier]\n",
    "        if path[0] not in data:\n",
    "            data[path[0]] = {}\n",
    "\n",
    "        data[path[0]][path[1]] = new_value\n",
    "        \n",
    "    current_scene_validation_amount = []\n",
    "    sets_candidates = []\n",
    "\n",
    "    identifier_first_level = list(data.keys())\n",
    "\n",
    "    for i in range(100):\n",
    "        current_validation_files = []\n",
    "        current_training_files = []\n",
    "\n",
    "        current_validation_identifiers2 = 0\n",
    "        for identifier1 in identifier_first_level:\n",
    "            current_ids = list(data[identifier1].keys())\n",
    "            random.shuffle(current_ids, random.random)\n",
    "\n",
    "            validation_split_index = int(numpy.ceil(0.3 * len(current_ids)))\n",
    "            current_validation = current_ids[0:validation_split_index]\n",
    "            current_training = current_ids[validation_split_index:]\n",
    "\n",
    "            for identifier2 in current_validation:\n",
    "                current_validation_files += data[identifier1][identifier2]\n",
    "\n",
    "            for identifier2 in current_training:\n",
    "                current_training_files += data[identifier1][identifier2]\n",
    "\n",
    "            current_validation_identifiers2 += len(current_validation)\n",
    "            \n",
    "        current_scene_validation_amount.append(\n",
    "            len(current_validation_files) / float(\n",
    "                len(current_validation_files) + len(current_training_files))\n",
    "        ) # 전체 v파일에 대해서 validation_files의 비율\n",
    "\n",
    "        sets_candidates.append({\n",
    "            'validation': current_validation_files,\n",
    "            'training': current_training_files,\n",
    "            'validation_identifiers1': len(identifier_first_level),\n",
    "            'validation_identifiers2': current_validation_identifiers2,\n",
    "        })\n",
    "\n",
    "    best_set_id = numpy.argmin(numpy.abs(numpy.array(current_scene_validation_amount) - 0.3))\n",
    "\n",
    "    validation_files += sets_candidates[best_set_id]['validation']\n",
    "    training_files += sets_candidates[best_set_id]['training']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train set: ', len(training_files))\n",
    "print('val set: ', len(validation_files))\n",
    "print('test set: ', len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name1 = '3class_melspecdelta_6'\n",
    "\n",
    "\n",
    "item_list_train = []\n",
    "item_list_validation = []\n",
    "item_list_test = []\n",
    "\n",
    "for item in meta_db:\n",
    "    _, current_last_level_path = os.path.split(item[\"filename\"])\n",
    "    base_filename, _ = os.path.splitext(current_last_level_path)\n",
    "\n",
    "    feature_filename1 = os.path.join(data_fold+'features/'\n",
    "                                     +feature_name1+'/'+base_filename+'.npz')\n",
    "\n",
    "    item_ = {\n",
    "        'data': {\n",
    "            'filename':[feature_filename1]\n",
    "        },\n",
    "        'meta': {\n",
    "            'label': item[\"scene_label\"]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if item[\"filename\"] in test_files:\n",
    "        item_list_test.append(item_)\n",
    "    elif item[\"filename\"] in training_files:\n",
    "        item_list_train.append(item_)\n",
    "    elif item[\"filename\"] in validation_files:\n",
    "        item_list_validation.append(item_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "Y_train = []\n",
    "for item in item_list_train:\n",
    "    binary_matrix = numpy.zeros((len(scene_labels), 1))\n",
    "    pos = scene_labels.index(item[\"meta\"][\"label\"])\n",
    "    binary_matrix[pos,:] = 1\n",
    "    \n",
    "    audio = numpy.load(item[\"data\"][\"filename\"][0])\n",
    "    embedding = audio['embedding']\n",
    "    \n",
    "    X_train.append(embedding)\n",
    "    Y_train.append(binary_matrix.T)\n",
    "    \n",
    "\n",
    "X_train = numpy.array(X_train)\n",
    "Y_train = numpy.vstack(Y_train)\n",
    "\n",
    "\n",
    "X_val = []\n",
    "Y_val = []\n",
    "for item in item_list_validation:\n",
    "    binary_matrix = numpy.zeros((len(scene_labels), 1))\n",
    "    pos = scene_labels.index(item[\"meta\"][\"label\"])\n",
    "    binary_matrix[pos,:] = 1\n",
    "    \n",
    "    audio = numpy.load(item[\"data\"][\"filename\"][0])\n",
    "    embedding = audio['embedding']\n",
    "    \n",
    "\n",
    "    X_val.append(embedding)\n",
    "    Y_val.append(binary_matrix.T)\n",
    "    \n",
    "\n",
    "X_val = numpy.array(X_val)\n",
    "Y_val = numpy.vstack(Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "Y_test = []\n",
    "for item in item_list_test:\n",
    "    binary_matrix = numpy.zeros((len(scene_labels), 1))\n",
    "    pos = scene_labels.index(item[\"meta\"][\"label\"])\n",
    "    binary_matrix[pos,:] = 1\n",
    "    \n",
    "    audio = numpy.load(item[\"data\"][\"filename\"][0])\n",
    "    embedding = audio['embedding']\n",
    "    \n",
    "    X_test.append(embedding)\n",
    "    Y_test.append(binary_matrix.T)\n",
    "    \n",
    "\n",
    "X_test = numpy.array(X_test)\n",
    "Y_test = numpy.vstack(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('deltas-deltadelta train shape: ',X_train.shape)\n",
    "print('deltas-deltadelta validation shape: ', X_val.shape)\n",
    "print('deltas-deltadelta test shape: ',X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_test_labels=[]\n",
    "for i in item_list_test:\n",
    "    if i['meta']['label']=='indoor':\n",
    "        dev_test_labels.append(0)\n",
    "    elif i['meta']['label']=='transportation':\n",
    "        dev_test_labels.append(1)\n",
    "    else:\n",
    "        dev_test_labels.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_val_labels=[]\n",
    "for i in item_list_validation:\n",
    "    if i['meta']['label']=='indoor':\n",
    "        dev_val_labels.append(0)\n",
    "    elif i['meta']['label']=='transportation':\n",
    "        dev_val_labels.append(1)\n",
    "    else:\n",
    "        dev_val_labels.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Mixup import MixupGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "\n",
    "import numpy\n",
    "import random\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import ZeroPadding2D,Input,Add, Permute, Cropping2D, Activation, Maximum,Dropout, Flatten, Dense, Conv2D, MaxPooling2D, MaxPool2D,BatchNormalization, Convolution2D, ReLU, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization as BN\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint,ReduceLROnPlateau\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from tensorflow.keras.layers import  concatenate\n",
    "\n",
    "import tensorflow.keras\n",
    "\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Model_paper import resnet, resnet_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-ResNet RF-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_1_model = resnet_1(Input(X_train.shape[1:]))\n",
    "base_1_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(base_model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    model_name = 'base_conv_rf1_'+ str(i)\n",
    "    checkpoint=\"checkpoints-10times/\"+model_name+'_'+\"cp.h5\"\n",
    "    base_1_model.load_weights(checkpoint)\n",
    "    model_filename = os.path.join(\n",
    "        'models-10times/', model_name+'_'+'model.h5')\n",
    "    base_1_model.save(model_filename)  # 이미 저장함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    processed_files=[]\n",
    "    model_name = 'base_conv_rf1_'+ str(i)\n",
    "    model_filename = os.path.join(\n",
    "        'models-10times/', model_name+'_'+'model.h5')\n",
    "    \n",
    "    model=tensorflow.keras.models.load_model(model_filename)\n",
    "\n",
    "\n",
    "    import tensorflow.keras as keras\n",
    "    tf.keras.backend.set_floatx('float16')\n",
    "    ws = model.get_weights()\n",
    "    wsp = [w.astype(tf.keras.backend.floatx()) for w in ws]\n",
    "\n",
    "    # Create quantization model\n",
    "    model_input=Input(shape=X_train.shape[1:])\n",
    "\n",
    "    model_quant = resnet_1(model_input)\n",
    "    model_quant.set_weights(wsp)\n",
    "\n",
    "    fold_model_filename=os.path.join('models-10times/','quant_'+ model_name+ '_model.h5')\n",
    "\n",
    "\n",
    "    # Save the quantized model\n",
    "    model_quant.save(fold_model_filename)\n",
    "\n",
    "    processed_files.append(fold_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    # quant 전 모델\n",
    "    model_name = 'base_conv_rf1_'+ str(i)\n",
    "    \n",
    "    # quant 모델\n",
    "    fold_model_filename=os.path.join('models-10times/','quant_'+ model_name+ '_model.h5')\n",
    "    \n",
    "    model_quant=tensorflow.keras.models.load_model(fold_model_filename )\n",
    "\n",
    "    test_scores = model_quant.predict(X_test, verbose=1)\n",
    "    test_pred=np.argmax(test_scores,axis=1)\n",
    "\n",
    "    Overall_test_accuracy = np.sum(test_pred==dev_test_labels)/len(X_test)\n",
    "    print('Test accuracy:', Overall_test_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    # quant 전 모델\n",
    "    model_name = 'base_conv_rf1_'+ str(i)\n",
    "    \n",
    "    # quant 모델\n",
    "    fold_model_filename=os.path.join('models-10times/','quant_'+ model_name+ '_model.h5')\n",
    "    \n",
    "    model_quant=tensorflow.keras.models.load_model(fold_model_filename )\n",
    "\n",
    "    scores_test = model_quant.predict(X_val, verbose=1)\n",
    "    y_pred_test = np.argmax(scores_test,axis=1)\n",
    "    y_real = np.argmax(Y_val,axis=1)\n",
    "    Overall_accuracy = np.sum(y_pred_test==dev_val_labels)/len(X_val)\n",
    "    print('Val accuracy:', Overall_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
